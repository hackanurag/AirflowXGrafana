version: '1'
x-airflow-common:
  &airflow-common
  image: apache/airflow:2.9.0
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    AIRFLOW__SCHEDULER__STATSD_ON: 'true'
    AIRFLOW__SCHEDULER__STATSD_HOST: statsd-exporter
    AIRFLOW__SCHEDULER__STATSD_PORT: 8125
    AIRFLOW__SCHEDULER__STATSD_PREFIX: airflow
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
    - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
  depends_on:
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    container_name: postgres-airflow
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
      - POSTGRES_PORT=5432
    ports:
      - "5432:5432"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/postgres_db_volume_airflow:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  airflow-webserver:
    <<: *airflow-common
    entrypoint: /bin/bash
    command: 
      - -c
      - airflow webserver
    ports:
      - "8080:8080"
    container_name: airflow_webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    entrypoint: /bin/bash
    command: 
      - -c
      - airflow scheduler
    container_name: airflow_scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - ( airflow users list && List of existong users... Airflow DB initialization completed............ ) || (airflow db init &&
        airflow users create
          --role Admin 
          --username webadmin
          --password airflow 
          --email anurag.datta.d@gmail.com
          --firstname Airflow
          --lastname webadmin  && echo DB initialized and user created &&  airflow users list)
    restart: on-failure
    
  statsd-exporter:
    image: prom/statsd-exporter #receives StatsD-style metrics and exports them as Prometheus metrics.
    volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/config/statsd.yaml:/opt/airflow/statsd.yaml
    container_name: airflow-statsd-exporter
    command: "--statsd.mapping-config=/opt/airflow/statsd.yaml --statsd.listen-udp=:8125 --web.listen-address=:9102"
    ports:
        - 9102:9102
        - 8125:8125/udp

  postgres-load:
      image: postgres:13
      container_name: postgres-load
      environment:
        - POSTGRES_USER=load
        - POSTGRES_PASSWORD=load
        - POSTGRES_DB=load
        - POSTGRES_PORT=5432
      ports:
        - "5433:5432"
      volumes:
        - ${AIRFLOW_PROJ_DIR:-.}/postgres_db_volume_load:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "load"]
        interval: 10s
        retries: 5
        start_period: 5s
      restart: always

  prometheus:
    image: prom/prometheus
    container_name: airflow-prometheus
    ports:
        - 9090:9090
    volumes:
        - ${AIRFLOW_PROJ_DIR:-.}/config/prometheus.yml:/etc/prometheus/prometheus.yml
        
volumes:
  postgres-db-volume: